{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "\n",
    "project='' #setup gcp project name/id\n",
    "client = bigquery.Client(project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(client.list_datasets()) #get all datasets available in bq [dependency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all table columns name and type of all tables available in bq\n",
    "# dfs=[]\n",
    "# for dataset in datasets:\n",
    "#     dname=dataset.dataset_id\n",
    "#     print(\"\\t{}\".format(dataset.dataset_id))\n",
    "#     dfs.append(\n",
    "#         client.query(f'SELECT table_schema, table_name, column_name, is_nullable, data_type FROM `{project}.{dname}.INFORMATION_SCHEMA.COLUMNS`').to_dataframe()\n",
    "#     )\n",
    "\n",
    "# all_table_columns=pandas.concat(dfs)\n",
    "#all_table_columns[all_table_columns['column_name'] == 'have_more_than_one_status'] # verify of what table is one column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tplayground\n",
      "\traw_data\n",
      "\tready_for_use\n",
      "\tstaging_data\n"
     ]
    }
   ],
   "source": [
    "#get all table and views name of all datasets in bq\n",
    "dfs=[]\n",
    "for dataset in datasets:\n",
    "    dname=dataset.dataset_id\n",
    "    print(\"\\t{}\".format(dataset.dataset_id))\n",
    "    dfs.append(\n",
    "        client.query(f'SELECT * FROM `{project}.{dname}.__TABLES__`').to_dataframe()\n",
    "    )\n",
    "\n",
    "all_t_and_views=pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tplayground\n",
      "\traw_data\n",
      "\tready_for_use\n",
      "\tstaging_data\n"
     ]
    }
   ],
   "source": [
    "#get all procedure names and sql of all datasets in bq\n",
    "dfs=[]\n",
    "for dataset in datasets:\n",
    "    dname=dataset.dataset_id\n",
    "    print(\"\\t{}\".format(dataset.dataset_id))\n",
    "    dfs.append(\n",
    "        client.query(f'SELECT * FROM `{project}.{dname}.INFORMATION_SCHEMA.ROUTINES`').to_dataframe()\n",
    "    )\n",
    "\n",
    "all=pandas.concat(dfs)\n",
    "all['routine_id']=all[['routine_catalog', 'routine_schema', 'routine_name']].agg('.'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessica.mitiko_dp6\\AppData\\Local\\Temp\\ipykernel_17036\\219949201.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  views['view_id']=views[['project_id', 'dataset_id', 'table_id']].agg('.'.join, axis=1)\n"
     ]
    }
   ],
   "source": [
    "views=all_t_and_views[all_t_and_views['type'] == 2] #depends on #get all table and views name of all datasets in bq\n",
    "views['view_id']=views[['project_id', 'dataset_id', 'table_id']].agg('.'.join, axis=1)\n",
    "\n",
    "#get all views and its query from bq\n",
    "view_ids=list(views['view_id'])\n",
    "a=[]\n",
    "for view_id in view_ids:\n",
    "    try:\n",
    "        view = client.get_table(view_id)\n",
    "        a.append((view_id, view.view_query))\n",
    "    except:\n",
    "        print(f'ERROR: maybe the view does not exist // {view_id}')\n",
    "\n",
    "all_views=pandas.DataFrame(columns=['view_id', 'query'], data=a)\n",
    "\n",
    "all_views['view_name']=all_views['view_id'].apply(lambda x:x.split('.')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all[all['routine_definition'].str.contains('exp_transactions.A2_cleaned_syn_view')][['routine_name', 'specific_schema']] #get all procedures where this substring exists\n",
    "# all_views[all_views['query'].str.contains('exp_transactions.A2_cleaned_syn_view')][['view_name', 'view_id']] #get all views where this substring exists\n",
    "\n",
    "#get all procedures and views where one or more substrings in the list exists\n",
    "# tbs=['dataset.view_name', 'dataset.procedure_name']\n",
    "# for tb in tbs:\n",
    "#     r=all[all['routine_definition'].str.contains(tb)]['routine_name']\n",
    "#     v=all_views[all_views['query'].str.contains(tb)]['view_name']\n",
    "\n",
    "#     print(f'\\n\\n{tb} \\nr: {r} \\nv: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all table, view and procedure path id to use as source vertices for the graph\n",
    "import re\n",
    "all_t_and_views['table_id_without_numeric_suffix']=all_t_and_views['table_id'].apply(lambda x:re.sub(r'_[0-9]+$', '_', x)) #remove date suffix from all tables where is present\n",
    "\n",
    "dfs=[]\n",
    "#all tables and views\n",
    "dfs.append(\n",
    "    all_t_and_views[['project_id', 'dataset_id', 'table_id_without_numeric_suffix']].agg('.'.join, axis=1))\n",
    "#all procedures\n",
    "dfs.append(\n",
    "    all[['routine_catalog', 'routine_schema', 'routine_name']].agg('.'.join, axis=1))\n",
    "\n",
    "r_all=list(pandas.concat(dfs).unique()) #all table, view and procedure path id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all nodes and edges [important!] external tables will NOT appear as a source so it will not appear in the graph, this occurs because all sources (tables, views and procedures) are query from {project}, but if you need to see external relations you can query others projects and concat it on one dataframe (r_all / real_all)\n",
    "edges=[]\n",
    "titles=[]\n",
    "\n",
    "tbs=list(r_all)\n",
    "for tb in tbs:\n",
    "    r=all[all['routine_definition'].str.contains(tb)]['routine_id'] #dependent routines\n",
    "    v=all_views[all_views['query'].str.contains(tb)]['view_id'] #dependent views\n",
    "\n",
    "    dependencies = list(v) + list(r) \n",
    "    #f=lambda x:x #do nothing\n",
    "    get_name=lambda x:re.search(r'[A-Za-z0-9_-]+$', x).group(0) #get view, procedure or table name\n",
    "    get_dataset=lambda x:re.search(r'^[a-zA-Z0-9-]+\\.([A-Za-z_]+)', x).group(1)\n",
    "    #            (source,          destination,    edge title                                  )\n",
    "    edges=edges+[(get_dataset(tb), get_dataset(d), f'{get_name(d)}\\n [...] FROM {get_name(tb)}') for d in dependencies if not tb == d] # [(source, dependency)]\n",
    "\n",
    "#for dataset graph remove circular reference\n",
    "edges=list(set(edges))\n",
    "edges=[(a, b, c) for (a, b, c) in edges if not a == b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without edge title\n",
    "# import networkx as nx\n",
    "# from pyvis.network import Network\n",
    "\n",
    "# DG = nx.DiGraph()\n",
    "# DG.add_edges_from(edges)\n",
    "\n",
    "# net=Network(notebook=True, cdn_resources='in_line', directed =True)\n",
    "# net.from_nx(DG)\n",
    "\n",
    "# net.show('example.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viz/example1.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"viz/example1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fe708647d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with edge title\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "DG = nx.DiGraph()\n",
    "\n",
    "for x, y, z in edges:\n",
    "    DG.add_edge(x, y, title=z)\n",
    "\n",
    "net=Network(notebook=True, cdn_resources='in_line', directed=True)\n",
    "net.from_nx(DG)\n",
    "\n",
    "net.show('viz/example1.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e270b96573f5ca09b1cc954654045b5e29f95282ac4fd2760f7838c741ab939"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
